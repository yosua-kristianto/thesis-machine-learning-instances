#!meta

{"kernelInfo":{"defaultKernelName":"csharp","items":[{"aliases":[],"name":"csharp"},{"aliases":[],"languageName":"fsharp","name":"fsharp"}]}}

#!fsharp

#r "nuget: Newtonsoft.Json, 13.0.3"
#r "nuget: Deedle, 3.0.0"

#!markdown

# Data Uploader

This notebook is dedicated to helps uploading file by folders. Take notes that this notebook will be saved as F# Interactive file format anyway and run with `dotnet fsi` command. 

Background:
Found that Google Drive API have no capabilities to upload folder. Either we zip the thingy out, and then upload the file to the Google Drive, or we upload the folder through web. But, this approach is uncomfy, especially tracking which files are successfully uploaded or not is huge task for 500K of data. 

The main goal of this notebook / script is to upload the file, by giving folder path as its parameter to run upload script recursively. Also, tracking whether the file is successfully uploaded or not to prevent any duplications. 

#!fsharp

open System;
open System.IO;
open System.Diagnostics;
open System.Net.Http;
open System.Threading;
open Newtonsoft.Json;
open Deedle;

#!markdown

# Utilities

This part contains utilities / helper functions for this code.

1. Environment Variable
This function is used to get the environment variable from config.json file.

2. Telegram Service
This function is used to integrating with the Telegram API.

3. Write Log
This function is used to write logs locally.

#!fsharp

type RegisteredKeys = {
    TELEGRAM_BOT_ID: string
    CHAT_ID: int64
    YOLO_ANNOTATION_FOLDER_OUTPUT: string
    MSCOCO_ANNOTATION_FOLDER_INPUT: string
    MSCOCO_IMAGE_FOLDER: string
    YOLO_IMAGE_FOLDER: string
};

let EnvironmentVariable : RegisteredKeys =
    let envPath: string = "../../config.json";
    
    let environmentVariableJsonFile = File.ReadAllText(envPath);

    let configurationValue: RegisteredKeys = JsonConvert.DeserializeObject<RegisteredKeys>(environmentVariableJsonFile);

    configurationValue;

type TelegramRequestDTO = { 
    text: string 
    chat_id: int64
}

let telegramService (message: string) =
    
    // Request manipulation

    let currentDateTime = DateTime.Now.ToString("yyyy-MM-dd HH:mm:ss");
    let requestMessage = "["+currentDateTime+"] "+message;
    let request: TelegramRequestDTO = { text = requestMessage; chat_id = EnvironmentVariable.CHAT_ID; };


    use httpRequest = new HttpClient();
    let json = JsonConvert.SerializeObject request;
    use content = new StringContent (json, Encoding.UTF8, "application/json")

    async {
        let! response = httpRequest.PostAsync("https://api.telegram.org/bot"+EnvironmentVariable.TELEGRAM_BOT_ID+"/sendMessage", content) |> Async.AwaitTask
        response;
    } |> Async.RunSynchronously;

let WriteLog (message: string) (logType: string) =
    let currentTime = DateTime.Now;
    let currentTimeInString = currentTime.ToString("yyyy-MM-dd H:m:s.FFFF zzz")
    let currentDateInString = currentTime.ToString("yyyyMMdd")
    let logToBeWritten = sprintf "[%s][%s][DATA_UPLOADER] %s" currentTimeInString logType message
    let pathToLog = Path.Combine("../../logs/", sprintf "%s.log" currentDateInString);

    if not (File.Exists(pathToLog)) then
        if not (Directory.Exists("../../logs/")) then
            Directory.CreateDirectory("../../logs/") |> ignore;
        use stream = new StreamWriter(pathToLog, false);

        stream.WriteLine("");
        stream.Close();

    File.AppendAllText(pathToLog, logToBeWritten + "\n") |> ignore;

#!markdown

# Core Engine

This part contains the core functionality for this script. Containing integration with GDriveIntegrator Script through terminal handler to able to integrate F# with Python script. 

#!fsharp

let terminalHandler (script: string) =
    let osVersion = System.Environment.OSVersion.Platform;

    let processInfo =
        match osVersion with
        | PlatformID.Win32NT | PlatformID.Win32S | PlatformID.Win32Windows | PlatformID.WinCE ->
            printfn "Current OS: Windows"
            new ProcessStartInfo("powershell.exe", sprintf "/C %s" script)
        | PlatformID.Unix | PlatformID.MacOSX ->
            printfn "Current OS: Unix/Linux or macOS"
            new ProcessStartInfo("/bin/bash", sprintf "-c %s" script)
        | _ ->
            printfn "Unknown OS"
            failwithf "Y U N O other OS??!!"

    processInfo.RedirectStandardOutput <- true
    processInfo.RedirectStandardError <- true
    processInfo.UseShellExecute <- false
    processInfo.CreateNoWindow <- true

    use proc = new Process()
    proc.StartInfo <- processInfo
    proc.Start()
    proc.WaitForExit()

    let output = proc.StandardOutput.ReadToEnd()
    let error = proc.StandardError.ReadToEnd()

    printfn "Output: %s\n\n\n" output

#!markdown

## Main Script
This is where the management and uploading algorithm doing some works. 
Remember well that an fsx file script must be executed from its folder hierarchy. 
There will be several steps to be fulfilled:

1. Import folder settings pre-processing
2. Define commands pattern for the upload process
3. SQLite database integration
4. Upload handler

#!markdown

### 1. Import folder settings pre-processing

This first step of main code, is intended to take data from the csv file using Deedle data science tools in F#. Unfortunately, the data that came directly from `ReadCsv` function cannot be directly used to be iteration using for loops stuffs. So, what I discovered is that, the `Frame` thingy must be executed through the pipeline method in which are denoted with `|>` in this programming language. 

Algorithm steps:
1. Define DataFrame data structure
2. Define an array to hold the data from the CSV
3. ReadCsv
4. Iterate through the Frame, and append the data to the array from number 2

#!fsharp

// Step 1
type DataFrame = {
    FOLDER_CODE: string
    FOLDER_ID: string
    ORIGINAL_PATH: string
}

// Step 2
let mutable data: DataFrame array = [||];

// Step 3
// Check for data.csv availability. This part will throw an error if the data is not available
let dataframe: Frame<int, string> = Frame.ReadCsv("../../data.csv");

// Step 4
dataframe |> Frame.mapRows(fun key row -> 
        let rowRepresentable: DataFrame = {
            FOLDER_CODE = row.GetAs<string>("FOLDER_CODE");
            FOLDER_ID = row.GetAs<string>("FOLDER_ID");
            ORIGINAL_PATH = row.GetAs<string>("ORIGINAL_PATH");
        }
        
        data <- Array.append data [| rowRepresentable |];
    ) |> ignore;

data

#!markdown

### 2. Define Command Pattern

Every single dataset has their own treatment. The treatment itself, required to be matched as intended below:

1. SRGAN
- First of all, since the file is kind of being united within the folder, I need to define data for train-test-val. So from 500K of data, I decide to split the data into 8:1:1 for train:test:val. 

| Splits | Ratio |
|---|---|
| Train | 8 |
| Test | 1 |
| Val | 1 |

- The data to be uploaded are determined by LowRes version of the file. Basically you take the file name, search for any FOLDER CODE of SRGAN*, with file name of it.

2. DLA
- This thing already splitted so I don't really need to split the data. Just upload the data within the folder to the destinated Google Drive ID. 

I need a SQLite database for this operation.

#!fsharp

(*
    Algorithm below are applied to do the job:

    1. Collect all datas within csv file to be uploaded
    2. For every datas within the csv file:
    2.1 Navigate to the directory within the csv file
    2.2 For every files within the Directory
    2.2.1 Try to upload the file using GDrive Integrator script 
    2.2.2 If the upload is successful
    2.2.3 Save the file state as success within some persistance (Undetermined. May use SQLite)
    2.2.4 
*)

// let ProgressBarFactory (total : int) =
//     let updateProgress (current : int) =
//         let progress = float current / float total * 100.
//         printf "\rProgress: [%-20s] %.2f%%" (String.replicate (current * 20 / total) "#") progress
//         Console.Out.Flush() |> ignore

//     let dispose() =
//         printfn ""

//     { new System.IDisposable with
//         member this.Dispose() = dispose() }, updateProgress

// let totalIterations = 100
// let disposable, updateProgress = ProgressBarFactory totalIterations

// for e = 1 to 100 do
//     printfn "Doing iteration for process %d" e;
//     for i = 1 to totalIterations do
//         // Do your iteration work here
//         Thread.Sleep(100);
//         updateProgress i
//     disposable.Dispose()
